{"cells":[{"cell_type":"code","source":["import pandas as pd"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"599cfef1-44ed-4377-a612-d043be72a755"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["spark.conf.set(\"spark.sql.execution.arrow.enabled\", \"true\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2aba9d48-9529-4ea1-8883-2856739749dd"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["dbutils.fs.unmount(\"/mnt/alv\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0535c2c7-a3cf-4902-9c45-955e0601feed"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">/mnt/alv has been unmounted.\nOut[3]: True</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">/mnt/alv has been unmounted.\nOut[3]: True</div>"]}}],"execution_count":0},{"cell_type":"code","source":["def mount_blob(storage_account_name, access_key):\n  #access_key = dbutils.secrets.get(scope=\"storage\", key=storage_account_name)\n  mount_list = [\n    {\n      \"folder_name\": \"alv\",\n      \"message\" : \"Mount Azure Blob Storage (alv) in DBFS...\"\n    }       \n  ]\n  \n  for item in mount_list:\n    print(item['message'])    \n    folder_name = item['folder_name']\n    mount_point = '/mnt/{}'.format(folder_name)\n    blob_path = 'wasbs://{}@{}.blob.core.windows.net'.format(folder_name, storage_account_name)\n    config = \"fs.azure.account.key.{}.blob.core.windows.net\".format(storage_account_name)\n    try:\n      dbutils.fs.ls(mount_point)\n      print('{} has been mounted.'.format(mount_point))\n    except:\n      print('DBFS Mount does not exist, creating mount {}...'.format(mount_point))\n      \n      dbutils.fs.mount(\n        source = blob_path,\n        mount_point = mount_point,\n        extra_configs = {\n          config:access_key\n        }\n      )"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f45bebff-4153-4b5c-97af-ccfeef984db0"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["storageAccountName = 'bidseadlg2'\n# blobContainerName = 'alv'\nstorageAccountAccessKey = 'k/GjO0Yn78u+XwP1vaVq2dVaN5spq2YgHmk87K35a6+wt31nsXd4zA2YVaugWsmqcniI511OLHNdYxQZj2nvXQ=='\nmount_blob(storageAccountName, storageAccountAccessKey)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"950a3199-93d8-48cc-bbdd-ac710737b5ea"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Mount Azure Blob Storage (alv) in DBFS...\nDBFS Mount does not exist, creating mount /mnt/alv...\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Mount Azure Blob Storage (alv) in DBFS...\nDBFS Mount does not exist, creating mount /mnt/alv...\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["def read_data_to_dataframe(file_location):\n  file_type = \"csv\"\n  # CSV options\n  infer_schema = \"false\"\n  first_row_is_header = \"true\"\n  delimiter = \",\"\n  encoding = 'utf-8'\n\n  # The applied options are for CSV files. For other file types, these will be ignored.\n  df = spark.read.format(file_type) \\\n    .option(\"inferSchema\", infer_schema) \\\n    .option(\"header\", first_row_is_header) \\\n    .option(\"sep\", delimiter) \\\n    .option(\"encoding\", encoding) \\\n    .load(file_location)\n  return df"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"98729004-f913-4506-ac70-b99dcf1da68e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["def output_csv_file(df, path):\n   (df.coalesce(1) # uncomment this line to ensure that the data is written to just one file\n   .write\n   .option(\"header\", \"true\")\n   .option(\"sep\", \",\")\n   .option(\"encoding\", \"utf-8\")\n   .option(\"ESCAPE quote\", '\"')\n   .mode(\"overwrite\") # overwrite any pre-existing data at the path that we're writing to\n   .csv(path)\n  )"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2e6e80ee-9783-4526-9826-06f38ae1493b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["file_list = []\ndf_list = []\nfolder_path = '/mnt/alv/'\nfiles = dbutils.fs.ls(folder_path + 'TEST')\n\nfor f in files:\n  file_list.append(f.name)\n  print(file_list)\n  df = read_data_to_dataframe(f.path).toPandas()\n  df = df.rename(columns={df.columns[len(df.columns)-1]: 'SourceFile'})\n  df_list.append(df)\n\nprint(df.head())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c740b1f1-c9ce-4a37-8a2d-192e853438c3"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">[&#39;TEST_CN20 _201901.csv&#39;]\n[&#39;TEST_CN20 _201901.csv&#39;, &#39;TEST_CN20_201902.csv&#39;]\n     工廠        申請單號 項次 報廢狀態  ...      除帳物料文件  除帳數量  除帳內文            SourceFile\n0  CN20  A180922021  1   除帳  ...  4901310555   950  版本升級  TEST_CN20_201902.csv\n1  CN20  A180922021  2   除帳  ...  4901310555  1000  版本升級  TEST_CN20_201902.csv\n2  CN20  A180922021  3   除帳  ...  4901310555  5670  版本升級  TEST_CN20_201902.csv\n3  CN20  A180922021  4   除帳  ...  4901310555   150  版本升級  TEST_CN20_201902.csv\n4  CN20  A180922021  5   除帳  ...  4901310555   300  版本升級  TEST_CN20_201902.csv\n\n[5 rows x 36 columns]\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">[&#39;TEST_CN20 _201901.csv&#39;]\n[&#39;TEST_CN20 _201901.csv&#39;, &#39;TEST_CN20_201902.csv&#39;]\n     工廠        申請單號 項次 報廢狀態  ...      除帳物料文件  除帳數量  除帳內文            SourceFile\n0  CN20  A180922021  1   除帳  ...  4901310555   950  版本升級  TEST_CN20_201902.csv\n1  CN20  A180922021  2   除帳  ...  4901310555  1000  版本升級  TEST_CN20_201902.csv\n2  CN20  A180922021  3   除帳  ...  4901310555  5670  版本升級  TEST_CN20_201902.csv\n3  CN20  A180922021  4   除帳  ...  4901310555   150  版本升級  TEST_CN20_201902.csv\n4  CN20  A180922021  5   除帳  ...  4901310555   300  版本升級  TEST_CN20_201902.csv\n\n[5 rows x 36 columns]\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["df_combine = pd.concat(df_list)\ndf_combine = df_combine.dropna(axis = 1, how = 'all')\ndf_combine.info()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d63915c2-c16c-44bd-978d-b7ff1b6b31de"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;\nInt64Index: 18 entries, 0 to 8\nData columns (total 31 columns):\n #   Column       Non-Null Count  Dtype \n---  ------       --------------  ----- \n 0   工廠           18 non-null     object\n 1   申請單號         18 non-null     object\n 2   項次           18 non-null     object\n 3   報廢狀態         18 non-null     object\n 4   申請人員         18 non-null     object\n 5   成本中心         18 non-null     object\n 6   客戶代號         18 non-null     object\n 7   客戶名稱         18 non-null     object\n 8   物料           18 non-null     object\n 9   物料說明         18 non-null     object\n 10  批號           18 non-null     object\n 11  移倉物料文件       18 non-null     object\n 12  數量           18 non-null     object\n 13  SKU          18 non-null     object\n 14  每單位量         18 non-null     object\n 15  報廢原因         18 non-null     object\n 16  原因說明         18 non-null     object\n 17  幣別22         18 non-null     object\n 18  報廢金額(成本)     18 non-null     object\n 19  CNY報廢金額(成本)  18 non-null     object\n 20  結算金額         18 non-null     object\n 21  CNY結算金額      18 non-null     object\n 22  幣別27         18 non-null     object\n 23  報廢金額(銷售)     18 non-null     object\n 24  幣別29         18 non-null     object\n 25  本國貨幣金額       18 non-null     object\n 26  過帳日期         18 non-null     object\n 27  除帳物料文件       18 non-null     object\n 28  除帳數量         18 non-null     object\n 29  除帳內文         18 non-null     object\n 30  SourceFile   18 non-null     object\ndtypes: object(31)\nmemory usage: 4.5+ KB\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;\nInt64Index: 18 entries, 0 to 8\nData columns (total 31 columns):\n #   Column       Non-Null Count  Dtype \n---  ------       --------------  ----- \n 0   工廠           18 non-null     object\n 1   申請單號         18 non-null     object\n 2   項次           18 non-null     object\n 3   報廢狀態         18 non-null     object\n 4   申請人員         18 non-null     object\n 5   成本中心         18 non-null     object\n 6   客戶代號         18 non-null     object\n 7   客戶名稱         18 non-null     object\n 8   物料           18 non-null     object\n 9   物料說明         18 non-null     object\n 10  批號           18 non-null     object\n 11  移倉物料文件       18 non-null     object\n 12  數量           18 non-null     object\n 13  SKU          18 non-null     object\n 14  每單位量         18 non-null     object\n 15  報廢原因         18 non-null     object\n 16  原因說明         18 non-null     object\n 17  幣別22         18 non-null     object\n 18  報廢金額(成本)     18 non-null     object\n 19  CNY報廢金額(成本)  18 non-null     object\n 20  結算金額         18 non-null     object\n 21  CNY結算金額      18 non-null     object\n 22  幣別27         18 non-null     object\n 23  報廢金額(銷售)     18 non-null     object\n 24  幣別29         18 non-null     object\n 25  本國貨幣金額       18 non-null     object\n 26  過帳日期         18 non-null     object\n 27  除帳物料文件       18 non-null     object\n 28  除帳數量         18 non-null     object\n 29  除帳內文         18 non-null     object\n 30  SourceFile   18 non-null     object\ndtypes: object(31)\nmemory usage: 4.5+ KB\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# pandas dataframe to spark dataframe\ndf_spark = spark.createDataFrame(df_combine)\n# display(df_spark)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cef2e090-0fc4-465a-ae0e-ece945e25941"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["write_path = \"{}/TEST_merge\".format(folder_path)\noutput_csv_file(df_spark, write_path)\n\ntmp_files = dbutils.fs.ls(write_path)\noutput_file = [x for x in tmp_files if x.name.startswith(\"part-\")]\n\n# Move the wrangled-data CSV file from a sub-folder (wrangled_data_folder) to the root of the blob container\n# While simultaneously changing the file name\ndbutils.fs.mv(output_file[0].path, \"{}/TEST.csv\".format(folder_path))\ndbutils.fs.rm(write_path, recurse = True)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"80ad3357-fcb2-48db-b01f-ccc6792ecaf2"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[11]: True</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[11]: True</div>"]}}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9771b16b-c8f7-437a-92a8-306701192973"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"65b7d8eb-64e2-4b4d-8bb2-da75f89d49fa"}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"Merge_TEST","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":1293317480619824}},"nbformat":4,"nbformat_minor":0}
